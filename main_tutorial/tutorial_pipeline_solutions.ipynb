{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing with Python -- <font color='orange'>Tutorial Pipeline Solutions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  About this Tutorial -- <font color='orange'> Notes on the Solutions </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the **complete solutions** to the tutorial. For the best learning experience, *it is recommended that you first try to implement a solution yourself* (see `tutorial_pipeline.py`). Only come here if you are totally stuck or if you have a working solution and would like to double-check it.\n",
    "\n",
    "Note that there are multiple ways of implementing any particular step in the pipeline, so if your solution is different from the solution here, it is not necessarily wrong. However, *some solutions are better than others* because they are...\n",
    "\n",
    "1. ...more readable:\n",
    "    - When reading the code, it is obvious and clear what the code is doing\n",
    "    - The code is clearly commented to help others (and your future self) understand it\n",
    "\n",
    "\n",
    "2. ...more general:\n",
    "    - The code still works if there are minor changes to the data (e.g. size of the image being processed)\n",
    "    - The code can easily be transformed into a solution for a similar problem\n",
    "\n",
    "\n",
    "3. ...more computationally efficient:\n",
    "    - No unnecessary copies of large datasets are made (memory efficiency)\n",
    "    - Faster algorithms are used, e.g. array operations instead of loops (CPU efficiency)\n",
    "    - No unnecessary loading and writing of data (io efficiency)\n",
    "\n",
    "\n",
    "It is up to you to decide if your solution is better, equally good, or not as good as the solution presented here. Either way, we hope you can learn something by looking at our solutions. **:)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is only necessary if you're running Python v2.x\n",
    "from __future__ import division\n",
    "print 3/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The numerical array package numpy as np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font> \n",
    "\n",
    "Using the import command as above, follow the instructions in the comments below to import two additional modules that we will be using frequently in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The plotting module matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The image processing package scipy.ndimage as ndi\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side Note for Jupyter Notebook Users\n",
    "\n",
    "You can configure how the figures made by matplotlib are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set matplotlib backend\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing & Handling Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "We will now proceed to import some image data, verifying that we get what we expect and then further specifying the data we will work with. Before you start, it makes sense to have a quick look at the data in Fiji/ImageJ so you know what you are working with!\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Specify the filename\n",
    "# Create a string variable with the name of the file to be imported ('example_cells_1.tif')\n",
    "# Suggested name for the variable: filename\n",
    "# Note: If the file is not in your current working directory, the filename variable must contain the \n",
    "#       entire path to the file, for example r'/home/jack/data/example_cells_1.tif'. Note the r at\n",
    "#       the beginning of the string: it designates this string as a \"raw\" string, which helps to\n",
    "#       avoid problems with slashes and other special symbols\n",
    "filename = r'/home/jack/data/example_cells_1.tif'\n",
    "filename = 'example_cells_1.tif'   # XXX: DELETME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Load the image\n",
    "# Import the function 'imread' from the module 'tifffile'.\n",
    "from tifffile import imread\n",
    "\n",
    "# Load 'example_cells_1.tif' and store it in a variable.\n",
    "# Suggested name for the variable: img\n",
    "img = imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Check that everything is in order\n",
    "# Check that 'img' is a variable of type 'ndarray' - use Python's built-in function 'type'.\n",
    "print \"Loaded array is of type:\", type(img)\n",
    "\n",
    "# Print the shape of the array using the numpy-function 'shape'. \n",
    "# Make sure you understand the output; recall that the image has 2 color channels and is 930 by 780 pixels. \n",
    "print \"Loaded array has shape:\", img.shape\n",
    "\n",
    "# Check the datatype of the individual numbers in the array. You can use the array attribute 'dtype' to do so.\n",
    "print \"Loaded values are of type:\", img.dtype\n",
    "\n",
    "# SOLUTION NOTE: The dtype should be 'uint8', because these are unsigned 8-bit integer images.\n",
    "#                This means that the intensity values range from 0 to 255 in steps of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv) Allocate the green channel to a separate new variable\n",
    "# For segmentation, we will only work with the green channel, so we need to allocate it to a new variable. \n",
    "# The green channel in this image is the first channel (or channel 0 in python). \n",
    "# We can allocated it to a new variable by slicing the 'img' array.\n",
    "# Hint: Recall that the image has three dimensions, two (rows and columns) defining the size of the image \n",
    "#       in terms of pixels, and one defining the number of channels. To slice the array, you need to index  \n",
    "#       each dimension to specify what you want from it.\n",
    "#       For example, array A below has two dimensions.\n",
    "#         A = np.array([[1,2,3],[4,5,6]])\n",
    "#       To obtain all entries in the first row, we would slice like this:\n",
    "#         B = A[0,:]\n",
    "#       You can slice the 2D green channel out of the 3D 'img' array in a similar fashion. \n",
    "green = img[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v) Look at the image to confirm that everything worked as intended\n",
    "# Show one of the channels as an image; use pyplot's functions plt.imshow followed by plt.show. \n",
    "# Check the documentation for plt.imshow and note the parameters that can be specified, such as the color map (cmap)\n",
    "# and interpolation. Since you are working with scientific data, interpolation is unwelcome, so you should set it to\n",
    "# 'none'. The most common cmap for grayscale images is naturally 'gray'.\n",
    "# You may also want to adjust the size of the figure. You can do this by preparing the figure canvas with\n",
    "# the function plt.figure before calling plt.imshow. The canvas size is adjusted using the keyword argument\n",
    "# figsize when calling plt.figure.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Follow the instructions in the comments below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Create a variable for the smoothing factor sigma, which should be an integer value\n",
    "# After implementing the Gaussian smoothing function below, you can modify this variable \n",
    "# to find the ideal value of sigma.\n",
    "sigma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Perform the smoothing on the image\n",
    "# To do so, use the Gaussian filter function 'ndi.filters.gaussian_filter' from the \n",
    "# image processing package ndimage, which was imported at the start of the tutorial. \n",
    "# Check out the documentation of scipy to see how to implement this function. \n",
    "# Allocate the output to a new variable.\n",
    "green_smooth = ndi.filters.gaussian_filter(green,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the result using plt.imshow and plt.show\n",
    "# Compare with the original image visualized in the step above. \n",
    "# Does the output make sense? Is this what you expected? \n",
    "# Can you optimize sigma such that the image looks smooth without blurring the membranes too much?\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_smooth,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Implement the two steps of adaptive background subtraction:\n",
    "\n",
    "1. Use a strong \"mean filter\" to create the background image. This simply assigns each pixel the average value of its local neighborhood. Just like the Gaussian blur, it can be done by deconvolution, but this time using a \"uniform kernel\".\n",
    "\n",
    "2. Use the background image for thresholding. Pixels with higher values in the original image than in the background should be given the value 1 and pixels with lower values in the original image than in the background should be given the value 0. The resulting binary image should represent the cell membranes.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "# (i) Create a disk-shaped structuring element and asign it to a new variable.\n",
    "# Structuring elements are small binary images that indicate which pixels \n",
    "# should be considered as the 'neighborhood' of the central pixel. \n",
    "#\n",
    "# An example of a small disk-shaped SE would be this:\n",
    "#   0 0 1 0 0\n",
    "#   0 1 1 1 0\n",
    "#   1 1 1 1 1\n",
    "#   0 1 1 1 0\n",
    "#   0 0 1 0 0\n",
    "#\n",
    "# The equation below creates such structuring elements. \n",
    "# It is an elegant but complicated piece of code and at the moment it is not \n",
    "# necessary for you to understand it in detail. Use it to create structuring \n",
    "# elements of different sizes (by changing 'i') and find a way to visualize \n",
    "# the result.\n",
    "# \n",
    "# Try to answer the following questions: \n",
    "#   - Is the resulting SE really circular?  >>> Close enough for large i, not so much for small i\n",
    "#   - Can certain values of 'i' cause problems? If so, why?  >>> Even values create a slight asymmetry!\n",
    "#   - What value of i should used for the se? \n",
    "#     Note that, similar to the sigma in Gaussian smoothing, the size of the SE\n",
    "#     is first estimated based on the images and by thinking about what would \n",
    "#     make sense. Later, it can be optimized by trial and error.\n",
    "#     >>> My first guess was i=30 (about 3x the membrane diameter). \n",
    "#         I tried out some other values but ultimately stuck with this.\n",
    "i = 31\n",
    "struct = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "plt.imshow(struct,interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Create the background\n",
    "# Run a mean filter over the image using the disc SE and assign the output to a new variable.\n",
    "# Use the function 'skimage.filters.rank.mean' (you first need to import the 'skimage.filters.rank' module).\n",
    "# Think about why a mean filter is used and if a different function (e.g. minimum, maximum or median) \n",
    "# would work equally well.\n",
    "from skimage.filters import rank \n",
    "bg = rank.mean(green_smooth, selem=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the resulting background image. \n",
    "# Compare it to the images generated above. Does the outcome make sense?\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(bg,interpolation='none',cmap='gray',vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2  \n",
    "\n",
    "# (iv) Threshold the Gaussian-smoothed original image using the background image created in step 1 \n",
    "#      to obtain the cell membrane segmentation\n",
    "# Set pixels with higher values in the original than in the bg to 1 and pixels with lower values to 0. \n",
    "# You can use a \"relational operator\" to do this, since numpy arrays will automatically perform element-wise\n",
    "# comparisons when compared to other arrays of the same shape.\n",
    "green_mem = green_smooth >= bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v) Visualize and understand the output. \n",
    "# What do you observe? \n",
    "# Are you happy with this result as a membrane segmentation? \n",
    "# >>> Not really; there is too much stuff inside the cells!\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_mem,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Masks with Binary Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Improve the membrane segmentation from above with morphological operations.\n",
    "\n",
    "Specifically, use `binary hole filling` to get rid of the speckles of foreground pixels that litter the insides of the cells. Furthermore, try different other types of morphological filtering to see how they change the image and to see if you can improve the membrane mask even more, e.g. by filling in gaps.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Get rid of speckles using binary hole filling\n",
    "# Use the function ndi.binary_fill_holes for this. Be sure to read up on the docs to\n",
    "# understand exactly what it does. For this to work as intended, you will have to \n",
    "# invert the mask, which you can do using the function np.logical_not. Again, be\n",
    "# sure to understand why this has to be done.\n",
    "green_mem_holes_filled = ndi.binary_fill_holes(np.logical_not(green_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Try out other morphological operations to further improve the membrane mask\n",
    "# The various operations are available in ndimage, for example ndi.binary_closing.\n",
    "# Play around and see how the different functions affect the mask. Can you optimize\n",
    "# the mask, for example by closing gaps?\n",
    "# Note that the default SE for these functions is a square. Feel free to create a\n",
    "# new disc-shaped SE and see how that changes the outcome.\n",
    "# Also, if you pay close attention you will notice that some of these operations\n",
    "# introduce artifacts at the image boundaries. Can you come up with a way of\n",
    "# solving this?\n",
    "\n",
    "# New circular SE of appropriate size (size determined by trial and error)\n",
    "i = 15\n",
    "struct = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "\n",
    "# One solution to the boundary issues is padding with the reflection\n",
    "# 'Padding' means the addition of pixels to the image. This means the boundary issues\n",
    "# will happen outside of the 'actual' image, which can then be cropped out again.\n",
    "pad_size = i+1\n",
    "padded_mem = np.pad(green_mem_holes_filled,pad_size,mode='reflect')\n",
    "\n",
    "# Binary closing works well to round off the membranes and close gaps\n",
    "mem_final = ndi.binary_closing(np.logical_not(padded_mem),structure=struct)\n",
    "\n",
    "# This slicing crops the padded image back to the original size\n",
    "mem_final = mem_final[pad_size:-pad_size,pad_size:-pad_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the final result\n",
    "# At this point you should have a pretty neat membrane mask.\n",
    "# If you are not satisfied with the quality your membrane segmentation, you should go back \n",
    "# and fine tune size of the SE in the adaptive thresholding section and also optimize the\n",
    "# morphological cleaning operations.\n",
    "# Note that the quality of the membrane segmentation will have a significant impact on the \n",
    "# cell segmentation we will perform downstream.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(mem_final,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected Components Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Use your membrane segmentation for connected components labeling.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Label connected components\n",
    "# Use the function ndi.label from ndimage. \n",
    "# Note that this function labels foreground pixels (`1`), so you may need to invert your mask\n",
    "# again if your membrane mask is currently labeled as foreground.\n",
    "mem_final = np.logical_not(mem_final)\n",
    "cell_labels,_ = ndi.label(mem_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Visualize the output\n",
    "# Here, it is no longer ideal to use a 'gray' colormap, since we want to visualize that each\n",
    "# cell has a unique ID. Play around with different colormaps (check the docs to see what\n",
    "# types of colormaps are available) and choose one that you are happy with.\n",
    "# Take a close look at the picture and note mistakes in the segmentation. Depending on the\n",
    "# quality of your membrane mask, there will most likely be some cells that are falsely \n",
    "# labeled as the same cells; this is called \"under-segmentation\". We will resolve this\n",
    "# issue in the next step. Note that our downstream pipeline does not involve any steps to\n",
    "# resolve \"over-segmentation\", so you should fine-tune your membrane mask such that this\n",
    "# is not a common problem.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cell_labels,interpolation='none',cmap='inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Segmentation by Seeding & Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding by Distance Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Retrieve seeds using distance transformation.\n",
    "\n",
    "This involves the following three steps:\n",
    "\n",
    "1. Run the distance transform on your membrane mask.\n",
    "\n",
    "2. Due to irregularities in the membrane shape, the distance transform may have some smaller local maxima in addition to those at the center of the cells. This will lead to additional seeds, which will lead to over-segmentation. To resolve this problem, smoothen the distance transform by applying a dilation/maximum filter. \n",
    "\n",
    "3. Find the seeds by detecting local maxima. Optimize the seeding by changing the dilation in step 2, aiming to have exactly one seed for each cell.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Distance transform on thresholded membranes\n",
    "# Use the function ndi.distance_transform_edt.\n",
    "dist_trans = ndi.distance_transform_edt(mem_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Visualise the output and understand what you are seeing.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(dist_trans,interpolation='none',cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Dilate the distance threshold\n",
    "# Use ndi.filters.maximum_filter to dilate the distance transform.\n",
    "# Read the documentation to remind yourself how and where the structuring element can be defined with this function.\n",
    "# You can try different SE sizes and shapes. \n",
    "\n",
    "# Using again a circular SE\n",
    "i = 10\n",
    "struct = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "\n",
    "# Running the dilation\n",
    "dist_trans_dil = ndi.filters.maximum_filter(dist_trans, footprint=struct) \n",
    "\n",
    "# Visualizing again\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(dist_trans_dil, interpolation='none', cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv) Retrieve the local maxima (the 'peaks') in the distance transform\n",
    "# Use the function peak_local_max from the module skimage.feature. By default, this function will return the\n",
    "# indices of the pixels where the local maxima are. However, we instead need a boolean mask of the same shape \n",
    "# as the original image, where all the local maximum pixels are labeled as `1` and everything else as `0`.\n",
    "# This can be achieved by setting the keyword argument 'indices' to False.\n",
    "from skimage.feature import peak_local_max\n",
    "seeds = peak_local_max(dist_trans_dil, indices=False, min_distance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v) Visualize the output as an overlay on the original (smoothed) image\n",
    "# If you just look at the local maxima image, it will simply look like a bunch of distributed dots.\n",
    "# To get an idea if the seeds are well-placed, you will need to overlay these dots onto the original image.\n",
    "# To do this, it is important to first understand a key point about how the pyplot module works: \n",
    "# every plotting command is slapped on top of the previous plotting commands, until everything is ultimately \n",
    "# shown when plt.show is called. Hence, you can first plot the original input (or the smoothed) image and \n",
    "# then plot the seeds on top of it before showing both with 'plt.show'.\n",
    "# As you can see if you try this, you will not get the desired result because the zero values in seed array\n",
    "# are painted in black over the image you want in the background. To solve this problem, you need to mask \n",
    "# these zero values before plotting the seeds. You can do this by creating an appropriately masked array\n",
    "# using the function 'np.ma.array'. Check the docs to figure out how to do this.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(seeds,mask=seeds==0),interpolation='none',cmap='autumn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (vi) Optimize the seeding\n",
    "# Ideally, there should be exactly one seed for each cell.\n",
    "# If you are not satisfied with your seeding, go back to the dilation step above and optimize it to get \n",
    "# rid of additional maxima. You can also try using the keyword argument min_distance in peak_local_max \n",
    "# to solve cases where there are multiple small seeds at the center of a cell.\n",
    "# Note that good seeding is essential for a good segmentation with an expansion algorithm. However,\n",
    "# no segmentation is ever perfect, so it's okay if a few cells end up being oversegmented!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (vii) Label the seeds\n",
    "# Use connected component labeling to give each cell seed a unique ID number.\n",
    "seeds_labeled = ndi.label(seeds)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion by Watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Expand your seeds by means of a watershed expansion.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Perform watershed\n",
    "# Use the function watershed from the module skimage.morphology.\n",
    "# Use the labeled cell seeds and the smoothed membrane image as input.\n",
    "from skimage.morphology import watershed\n",
    "ws = watershed(green_smooth,seeds_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Show the result as transparent overlay over the smoothed input image\n",
    "# This can be done similar to the masked overlay of the seeds, but now you don't need to mask \n",
    "# the background in the overlayed image (there will be none, since everything gets labeled in\n",
    "# the watershed). Instead, you need to make the overlayed image semi-transparent. \n",
    "# This can be achieved using the optional argument 'alpha' of the 'plt.imshow' function \n",
    "# to specify the opacity.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(ws,interpolation='none',cmap='prism',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *A Note on Segmentation Quality*\n",
    "\n",
    "This concludes the segmentation of the cells in the example image. Depending on the quality you achieved in each step along the way, the final segmentation may be of greater or lesser quality (in terms of over-/under-segmentation errors).\n",
    "\n",
    "It should be noted that the segmentation will likely *never* be 'perfect'! This can't be helped because image segmentation is ultimately a `computational classification task` and all such tasks are subject to a fundamental trade-off between specificity and sensitivity, which in this case takes the form of a trade-off between over- and under-segmentation.\n",
    "\n",
    "This raises an important question: ***when should I stop trying to optimize my segmentation?***\n",
    "\n",
    "There is no absolute answer to this question, but the best answer is probably ***when you can use it to address your biological questions.***\n",
    "\n",
    "*Importantly, this implies that you should already have a relatively clear question in mind when you are working on the segmentation!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing: Removing Cells at the Image Border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Iterate through all the cells in your segmentation and remove those that are at the image border.\n",
    "\n",
    "Follow the instructions in the comments below. Note that the instructions will tend to be less specific from here on, so you need to figure out how to approach a problem yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Create image border mask\n",
    "# We need some way to check if a cell is at the border. For this, we generate a 'mask' of the image border,\n",
    "# i.e. a Boolean array of the same size as the image where only the border pixels are set to `1` and all \n",
    "# others to `0`, like this:\n",
    "#   1 1 1 1 1\n",
    "#   1 0 0 0 1\n",
    "#   1 0 0 0 1\n",
    "#   1 0 0 0 1\n",
    "#   1 1 1 1 1\n",
    "# There are multiple ways of generating this mask, for example by erosion or by array indexing.\n",
    "# It is up to you to find a way to do it.\n",
    "boundary_mask = np.ones(ws.shape,dtype=np.bool)\n",
    "boundary_mask = np.logical_not(ndi.binary_erosion(boundary_mask,border_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) 'Delete' the cells at the border:\n",
    "# Note: When modifying a segmentation (in this case by deleting some cells), it makes sense\n",
    "#       to work on a copy of the array, not on the original. This avoids unexpected behaviors,\n",
    "#       especially within jupyter notebooks. Use the function np.copy to copy an array.\n",
    "clean_ws = np.copy(ws)\n",
    "\n",
    "# Iterate over all cells in the segmentation. Use a for-loop and the function np.unique;\n",
    "# remember that each cell in our segmentation is labeled with a different integer.\n",
    "for cell_ID in np.unique(ws):\n",
    "\n",
    "    # Create a mask that contains only the 'current' cell in the iteration\n",
    "    # Hint: Remember that the comparison of an array with some number (array==number)\n",
    "    #       returns a Boolean mask of the pixels in 'array' whose value is 'number'.\n",
    "    cell_mask = ws==cell_ID \n",
    "    \n",
    "    # Using the cell mask and the border mask from above, test if the cell has pixels touching \n",
    "    # the image boundary or not.\n",
    "    # Hint: np.logical_and\n",
    "    cell_boundary_overlap = np.logical_and(cell_mask,boundary_mask)   # Overlap of cell mask and boundary mask\n",
    "    total_overlapping_pixels = np.sum(cell_boundary_overlap)          # Sum overlapping pixels\n",
    "    \n",
    "    # If a cell touches the image boundary, delete it by setting its pixels in the segmentation to 0.\n",
    "    if total_overlapping_pixels > 0: \n",
    "        clean_ws[cell_mask] = 0\n",
    "\n",
    "\n",
    "# OPTIONAL: re-label the remaining cells to keep the numbering consistant from 1 to N (with 0 as background).\n",
    "for new_ID,cell_ID in enumerate(np.unique(clean_ws)[1:]):  # The [1:] excludes 0 from the list (background)!\n",
    "    clean_ws[clean_ws==cell_ID] = new_ID+1                 # The same here for the +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the result\n",
    "# Show the result as transparent overlay over the original/blurred image. \n",
    "# Here you have to combine alpha (to show cells transparently) and 'np.ma.array'\n",
    "# (to hide empty space where the border cells were deleted).\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(clean_ws,mask=clean_ws==0),interpolation='none',cmap='prism',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Cell Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Create a labeled mask of cell edges by following these steps:\n",
    "\n",
    "\n",
    "- Create an empty array of the same size and data type as the segmentation\n",
    "    - This will be your final cell edge mask; you gradually add cell edges as you iterate over cells\n",
    "    \n",
    "\n",
    "- *For each cell:*\n",
    "    - Erode the cell's mask by 1 pixel\n",
    "    - Using the eroded mask and the original mask, create a new mask of only the cell's edge pixels\n",
    "    - Add the cell's edge pixels into the empty image generated above, labeling them with the cell's original ID number\n",
    "\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Create an empty array of the same size and data type as the segmentation\n",
    "# Hint: np.zeros_like(...) or np.zeros(...,dtype=...)\n",
    "edges = np.zeros_like(clean_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Iterate over the cells\n",
    "# Hint: np.unique\n",
    "for cell_ID in np.unique(clean_ws)[1:]:\n",
    "\n",
    "    # (iii) Erode the cell's mask by 1 pixel\n",
    "    # Hint: smart indexing and ndi.binary_erode\n",
    "    cell_mask = clean_ws==cell_ID\n",
    "    eroded_cell_mask = ndi.binary_erosion(cell_mask)\n",
    "    \n",
    "    # (iv) Create cell edge mask\n",
    "    # Hint: np.logical_xor\n",
    "    edge_mask = np.logical_xor(cell_mask,eroded_cell_mask)\n",
    "    \n",
    "    # (v) Add the cell edge mask to the empty array generated above, labeling it with the cell's ID\n",
    "    # Hint: smart indexing\n",
    "    edges[edge_mask] = cell_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (vi) Visualize the result\n",
    "# Note: Because the lines are so thin (1pxl wide), they may not be displayed correctly in small images.\n",
    "#       If you wish, you can try and find a solution for this problem. One simple option is just to\n",
    "#       show a (zoomed-in) sub-region of the image.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(edges),cmap='gray',vmin=0,vmax=1)  # Black background\n",
    "plt.imshow(np.ma.array(edges,mask=edges==0),interpolation='none',cmap='prism')\n",
    "plt.xlim((300,500))\n",
    "plt.ylim((300,500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Quantitative Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Extract the measurements listed above for each cell and collect them in a dictionary.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Create a dictionary that contains a key-value pairing for each measurement\n",
    "# The keys should be a strings describing the type of measurement (e.g. 'green_intensity_mean') \n",
    "# and the values should be empty lists. These empty lists will be filled with the results of \n",
    "# the measurements and the dictionary will make it easy to work with this data.\n",
    "results = {\"cell_id\":[],\n",
    "           \"green_mean\":[],\n",
    "           \"red_mean\":[],\n",
    "           \"green_mem_mean\":[],\n",
    "           \"red_mem_mean\":[],\n",
    "           \"cell_area\":[],\n",
    "           \"cell_edge\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Record the measurements for each cell\n",
    "# Iterate over the segmented cells (np.unique).\n",
    "# Inside the loop, create a mask for the current cell and use it to extract the measurements listed above. \n",
    "# Add them to the appropriate list in the dictionary using the list.append method.\n",
    "# Hint: Remember that you can get out all the values within a masked area by indexing the image \n",
    "#       with the mask. For example, np.mean(image[cell_mask]) will return the mean of all the \n",
    "#       intensity values of 'image' that are masked by 'cell_mask'.\n",
    "\n",
    "# Iterate over cell IDs\n",
    "for cell_id in np.unique(clean_ws)[1:]:\n",
    "\n",
    "    # Mask the current cell and cell edge\n",
    "    cell_mask = clean_ws==cell_id\n",
    "    edge_mask = edges==cell_id\n",
    "    \n",
    "    # Get the measurements\n",
    "    # Note: the .item() method ensures that the resulting number is converted from a numpy number object\n",
    "    #       (e.g. type np.float) to a native python number object (e.g. type float). For most purposes,\n",
    "    #       this is irrelevant, but for saving data in a python object as we do later on, it is useful\n",
    "    #       to use native python objects only.\n",
    "    results[\"cell_id\"].append(cell_id.item())\n",
    "    results[\"green_mean\"].append(np.mean(img[0,cell_mask]).item())\n",
    "    results[\"red_mean\"  ].append(np.mean(img[1,cell_mask]).item())\n",
    "    results[\"green_mem_mean\"].append(np.mean(img[0,edge_mask]).item())\n",
    "    results[\"red_mem_mean\"  ].append(np.mean(img[1,edge_mask]).item())\n",
    "    results[\"cell_area\"].append(np.sum(cell_mask).item())\n",
    "    results[\"cell_edge\"].append(np.sum(edge_mask).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Print the results and check that they make sense\n",
    "for key in results.keys(): print key, '\\n', results[key], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Analysis & Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Follow the instructions in the comments below.\n",
    "\n",
    "*Note:* If you're working in jupyter notebook, feel free to split the code cell below into multiple cells to make it easier to view the plots and modify the code without scrolling up and down all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Familiarize yourself with the data structure of the results dict and summarize the results\n",
    "# Recall that dictionaries are unordered; a dataset of interest is accessed through its key.\n",
    "# In our case, the datasets inside the dict are lists of values, ordered in the same order\n",
    "# as the cell IDs. \n",
    "# For each dataset in the results dict, print its name (the key) along with its mean, standard \n",
    "# deviation, maximum, minimum, and median. The appropriate numpy methods (e.g. np.median) work\n",
    "# with lists just as well as with arrays.\n",
    "\n",
    "# Custom function for printing summary statistics\n",
    "# Note the use of format strings for nice number padding.\n",
    "def print_summary(data):\n",
    "    print \"  Mean:    {:7.2f}\".format(np.mean(data))\n",
    "    print \"  Stdev:   {:7.2f}\".format(np.std(data))\n",
    "    print \"  Max:     {:7.2f}\".format(np.max(data))\n",
    "    print \"  Min:     {:7.2f}\".format(np.min(data))\n",
    "    print \"  Median:  {:7.2f}\".format(np.median(data))\n",
    "    \n",
    "# Calling the custom function for each dataset\n",
    "for key in results.keys():\n",
    "    print '\\n'+key\n",
    "    print_summary(results[key])\n",
    "    \n",
    "# There are also pre-made functions to get summary statistics,\n",
    "# for example scipy.stats.describe.\n",
    "from scipy.stats import describe\n",
    "stat_summary = describe(results['green_mean'])\n",
    "\n",
    "print '\\nscipy.stats.describe of green_mean'\n",
    "for key in stat_summary.__dict__.keys():\n",
    "    print ' ', key, stat_summary.__dict__[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Create a box plot showing the mean cell and mean membrane intensities for both channels. \n",
    "# Use the function plt.boxplot. Use the 'label' keyword of 'plt.boxplot' to label the x axis with \n",
    "# the corresponding key names. Feel free to play around with the various options of the boxplot \n",
    "# function to make your plot look nicer. Remember that you can first call plt.figure to adjust \n",
    "# settings such as the size of the plot.\n",
    "\n",
    "# Quick version\n",
    "boxplot_keys = ['green_mean','red_mean','green_mem_mean','red_mem_mean']\n",
    "plt.boxplot([results[key] for key in boxplot_keys],labels=boxplot_keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nice version\n",
    "\n",
    "# Get relevant keys\n",
    "boxplot_keys = ['green_mean','red_mean','green_mem_mean','red_mem_mean']\n",
    "\n",
    "# Set fig size and 'get current axis' (gca)\n",
    "# Working with the matplotlib axis object gives access to more settings.\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "# Create the box plot\n",
    "# Include a 'notched' shape at the median and allow the surface to be colored (patch_artist).\n",
    "bplot = ax.boxplot([results[key] for key in boxplot_keys],\n",
    "                   notch=True,patch_artist=True)\n",
    "\n",
    "# Set the boxplot surface colors and edge properties\n",
    "colors = ['#7BFF7B','#fb7b7b','#7BFF7B','#fb7b7b']  # Use hex colors to freely choose colors\n",
    "for patch,color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_edgecolor('gray')\n",
    "    patch.set_linewidth(2)\n",
    "\n",
    "# Choose colors and styles for whiskers, caps, medians and fliers\n",
    "plt.setp(bplot['whiskers'],color='gray',linestyle='-',lw=2)\n",
    "plt.setp(bplot['caps'],color='gray',lw=2)\n",
    "plt.setp(bplot['medians'],linestyle='none')\n",
    "plt.setp(bplot['fliers'],marker='D',markerfacecolor='red',\n",
    "         markeredgewidth=0,markersize=3)\n",
    "    \n",
    "# Set rotated xticklabels\n",
    "ax.set_xticklabels(boxplot_keys,rotation=45,ha='right')\n",
    "\n",
    "# Hide the right and top spines and ticks\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Label\n",
    "ax.set_title('Nice Boxplot of Mean Intensities')\n",
    "ax.set_ylabel('Mean Intensity [a.u.]')\n",
    "\n",
    "# All done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Create a scatter plot of red membrane intensity over cell area\n",
    "# Use the function plt.scatter for this. Be sure to properly label the plot using\n",
    "# plt.xlabel and plt.ylabel.\n",
    "plt.scatter(results[\"cell_area\"],results[\"red_mem_mean\"])\n",
    "plt.xlabel(\"cell size [pxl]\")\n",
    "plt.ylabel(\"red_membrane_mean [a.u]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv) Perform a linear fit of red membrane intensity over cell area\n",
    "# Use the functions linregress from the module scipy.stats. Be sure to read the docs to\n",
    "# understand the output of this function. Print the output. In addition to R, also\n",
    "# calculate and print R-squared.\n",
    "from scipy.stats import linregress\n",
    "linfit = linregress(results[\"cell_area\"],results[\"red_mem_mean\"])\n",
    "linprops = ['slope','interc','rval','pval','stderr']\n",
    "for index,prop in enumerate(linprops):\n",
    "    print prop, '\\t', '{:4.2e}'.format(linfit[index])\n",
    "print 'r-sqrd', '\\t', '{:4.2e}'.format(linfit[2]**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v) Think about the result\n",
    "# Note that the fit seems to return a highly significant p-value but a very low correlation coefficient (r-value). \n",
    "# Based on prior knowledge, we would not expect a linear correlation to be present in our data. \n",
    "# This should prompt several questions:\n",
    "#\n",
    "#   1) What does this p-value actually mean? Check the docs of linregress!\n",
    "#       SOLUTION NOTE: This p-value tells us that it is unlikely for red_mem_mean and cell_area to be \n",
    "#                      completely independent. However, it does not tell us that the two are related\n",
    "#                      by a linear relationship; in fact, the low correlation coefficient tells us\n",
    "#                      that this is probably not the case.\n",
    "#\n",
    "#   2) Could there be artifacts in our segmentation that bias this analysis?\n",
    "#       SOLUTION NOTE: Oversegmentation is an important source of bias here. If a cell is oversegmented,\n",
    "#                      it will be considered as two or three cells. These will naturally have a lower\n",
    "#                      cell area and will naturally have a lower membrane intensity (because some of their\n",
    "#                      edges are actually not on membranes). In other words, they will fall into the bottom\n",
    "#                      left of the plot, distorting the data.\n",
    "#\n",
    "#   3) With single-cell analysis, we quickly get to a large number of datapoints. \n",
    "#      This can skew statistical analyses and should be accounted for by multiple\n",
    "#      testing correction and/or by comparison with randomized datasets.\n",
    "#\n",
    "# In general, it's always good to be very careful when doing data analysis. Make sure you understand the functions \n",
    "# you are using and always check for possible errors or biases in your analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (vi) Overlay the linear fit onto the scatter plot\n",
    "# Recall that a linear function is defined by `y = slope * x + intercept`.\n",
    "\n",
    "# To define the line you'd like to plot, you need two values of x (the starting point and\n",
    "# and the end point of the line). What values of x make sense?\n",
    "# SOLUTION NOTE: The max and min values in the data, so the line will span the entire dataset.\n",
    "x_vals = [min(results[\"cell_area\"]),max(results[\"cell_area\"])]\n",
    "\n",
    "# When you have the x-values for the starting point and end point, get the corresponding y \n",
    "# values from the fit using the equation above.\n",
    "y_vals = [linfit[0] * x_vals[0] + linfit[1], linfit[0] * x_vals[1] + linfit[1]]\n",
    "\n",
    "# Plot the line with plt.plot. Adjust the line's properties so it is well visible.\n",
    "# Hint: remember that you will have to re-create the scatterplot before plotting the line, \n",
    "# so that the line will be placed on top of the scatterplot.\n",
    "plt.scatter(results[\"cell_area\"],results[\"red_mem_mean\"],linewidth=0,s=10)\n",
    "plt.plot(x_vals,y_vals,color='red',lw=2)\n",
    "\n",
    "# Use plt.legend to add information about the line to the plot.\n",
    "plt.legend([\"linear fit, R={:4.2e}\".format(linfit[2])])\n",
    "\n",
    "# Label the plot and finally show it with plt.show.\n",
    "plt.xlabel(\"cell size [pxl]\")\n",
    "plt.ylabel(\"red_membrane_mean [a.u.]\")\n",
    "plt.title(\"Scatterplot with linear fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (vii) Map the cell area back onto the image as a 'heatmap'\n",
    "# Scale the cell area data to 8bit so that it can be used as pixel intensity values.\n",
    "# Hint: if the largest cell area should correspond to the value 255 in uint8, then \n",
    "#       the other cell areas correspond to cell_area*255/largest_cell_area.\n",
    "# Hint: To perform an operation on all cell area values at once, convert the list \n",
    "#       of cell areas to a numpy array.\n",
    "areas_8bit = np.array(results[\"cell_area\"]) / max(results[\"cell_area\"]) * 255\n",
    "\n",
    "# Initialize a new image; all values should be zeros, the shape should be identical to\n",
    "# the images we worked with before and the dtype should be uint8.\n",
    "area_map = np.zeros_like(clean_ws,dtype=np.uint8) \n",
    "\n",
    "# Iterate over the segmented cells (np.unique). In addition to the cell IDs, the\n",
    "# for-loop should also include a simple counter (starting from 0) with which the area\n",
    "# data can be accessed.\n",
    "for index,cell_id in enumerate(np.unique(clean_ws)[1:]):\n",
    "    \n",
    "    # Mask the current cell and assign the cell's (re-scaled) area to the cell's pixels.\n",
    "    area_map[clean_ws==cell_id] = areas_8bit[index]\n",
    "\n",
    "    \n",
    "# Visualize the result as a colored semi-transparent overlay over the raw/smoothed original input image.\n",
    "# Optional: See if you can exclude outliers to make the colormapping more informative!\n",
    "\n",
    "# Mask of outliers (the largest and smallest 5% of all cells)\n",
    "outlier_mask = np.logical_or(area_map>np.percentile(areas_8bit,95),\n",
    "                             area_map<np.percentile(areas_8bit,5))\n",
    "\n",
    "# Mask of all regions to leave blank (outliers + image boundary cells)\n",
    "full_mask = np.logical_or(area_map==0,outlier_mask)\n",
    "\n",
    "# Make the plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(area_map,mask=full_mask),\n",
    "           interpolation='none',cmap='jet',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Output to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Write one or more of the images you produced to a tif file\n",
    "# Use the function imsave from the tifffile module. Make sure that the array you are writing\n",
    "# is of integer type. If necessary, you can use the method 'astype' for conversions, e.g.\n",
    "# some_array.astype(np.uint8).\n",
    "# You can also try adding the segmentation to the original image, creating an image with\n",
    "# three channels, one of them being the segmentation. \n",
    "# After writing the file, load it into Fiji and check that everything worked as intended.\n",
    "from tifffile import imsave\n",
    "imsave(\"example_cells_1_edges.tif\",edges.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Write a figure to a png or pdf\n",
    "# Recreate the scatter plot from above (with or without the regression line), then save the figure\n",
    "# as a png using plt.savefig. Alternatively, you can also save it to a pdf, which will create a\n",
    "# vector graphic that can be imported into programs like Adobe Illustrator.\n",
    "\n",
    "# Create plot (but don't show)\n",
    "plt.scatter(results[\"cell_area\"],results[\"red_mem_mean\"],linewidth=0,s=10)\n",
    "plt.plot(x_vals,y_vals,color='red',lw=2)\n",
    "plt.legend([\"linear fit, R={:4.2e}\".format(linfit[2])])\n",
    "plt.xlabel(\"cell size [pxl]\")\n",
    "plt.ylabel(\"red_membrane_mean [a.u.]\")\n",
    "plt.title(\"Scatterplot with linear fit\")\n",
    "\n",
    "# Save as png and pdf\n",
    "plt.savefig('example_cells_1_scatterFit.png')\n",
    "plt.savefig('example_cells_1_scatterFit.pdf')\n",
    "plt.clf()  # Clear the figure buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Save the segmentation as a numpy file\n",
    "# Numpy files allow fast storage and reloading of numpy arrays. Use the function np.save to save\n",
    "# the array and reload it using np.load.\n",
    "np.save(\"example_cells_1_seg\",clean_ws)  # Save\n",
    "#seg = np.load(\"example_cells_1_seg.npy\") # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv) Save the result dictionary as a json file\n",
    "# Json files are generic files that can save almost any python object and reload it again.\n",
    "# You will need to open an empty file object using \"open\" in write mode ('w'). It's best to do so\n",
    "# using the 'with'-statement (context manager) to make sure that the file object will be closed\n",
    "# automatically when you are done with it. Use the function json.dump to write the results to\n",
    "# the file.\n",
    "# Hint: Refer to the python documention for input and output to understand how file objects are\n",
    "#       handled in python in general.\n",
    "# NOTE: Json can only handle ('serialize') native python objects, which does not include numpy\n",
    "#       objects (arrays and numpy number types). If you run into problems with this, go back to \n",
    "#       the section 'Extracting Quantitative Measurements' and convert the values you write into \n",
    "#       the result dict into native python numbers. You can do this with numpy's .item() method.\n",
    "import json\n",
    "with open('example_cells_1_results.json','w') as outfile:\n",
    "    json.dump(results,outfile)\n",
    "\n",
    "## Note: json files can be re-loaded again as follows:\n",
    "#with open('example_cells_1_results.json', 'r') as infile:\n",
    "#    results = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v) Write a tab-separated text file of the results dict\n",
    "# The most generic way of saving numerical results is a simple text file. It can be imported into \n",
    "# pretty much any other program.\n",
    "\n",
    "# To write normal text files, open an empty file object in write mode ('w') using the 'with'-statement.\n",
    "with open('example_cells_1_results.txt','w') as outfile:\n",
    "\n",
    "    # Use the file_object.write(string) method to write strings to the file. First write the header of the\n",
    "    # date (the result dict keys), separated by tabs ('\\t'). It makes sense to first generate a complete\n",
    "    # string with all the headers and then write this string to the file. Note that you will need to \n",
    "    # explicitly write 'newline' characters ('\\n') at the end of the line to switch to the next line.\n",
    "    sorted_keys = sorted(results.keys())\n",
    "    header_string = '\\t'.join(sorted_keys) + '\\n'\n",
    "    outfile.write(header_string)\n",
    "\n",
    "    # After writing the headers, iterate over all the cells saved and write the data to the file by\n",
    "    # creating strings similar to the header string.\n",
    "    for index in range(len(results['cell_id'])):\n",
    "        data_string = '\\t'.join([str(results[key][index]) for key in sorted_keys]) + '\\n'\n",
    "        outfile.write(data_string)\n",
    "        \n",
    "# After writing the data, have a look at the output file in a text editor or in a spreadsheet\n",
    "# program like Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='orange'> Exercise Solution </font>\n",
    "\n",
    "To run a pipeline multiple times, it needs to be packaged as a function or even as a module. Jupyter notebook is not well suited for this, so if you're working in a notebook, first extract your code to a .py file (see instructions below). If you are not working in a notebook, create a copy of your pipeline; we will modify this copy into a function that can then be called repeatedly for different images.\n",
    "\n",
    "To export a jupyter notebook as a .py file, use `File > Download as > Python (.py)`, then save the file. Open the resulting python script in a text editor or in an IDE like Spyder. \n",
    "\n",
    "\n",
    "**Let's clean the script a bit:**\n",
    "\n",
    "- Remove the line `%matplotlib [inline|notebook|qt]`. It is not valid python code outside of a notebook\n",
    "\n",
    "\n",
    "- Go through the script and comment out everything related to plotting; when running a pipeline for dozens or hundreds of images, we usually do not want it to generate tons of plots\n",
    "\n",
    "\n",
    "- Similarly, it can make sense to remove some print statments if you have many of them.\n",
    "\n",
    "\n",
    "- Remove the sections `Simple Analysis and Visualization` and `Writing Output to Files`; we will collect the output for each image within python and then analyze everything at once\n",
    "\n",
    "\n",
    "- Feel free to delete the background information to make the script more concise.\n",
    "\n",
    "\n",
    "**Converting the pipeline to a function:**\n",
    "\n",
    "Convert the entire pipeline into a function that accepts a filename as input, runs everything, and returns the final segmentation and the results dictionary. To do this, you must:\n",
    "\n",
    "- Add the function definition statement at the beginning of the script (after the imports)\n",
    "- Replace the 'hard-coded' filename by a variable that is accepted by the function\n",
    "- Indent all the code\n",
    "- Add a return statement at the end\n",
    "\n",
    "<br><font color='orange'>**SOLUTION NOTE:**</font> The cleaned and ready to go batch version for the solutions is named `tutorial_pipeline_solutions_batch.py`<br><br>\n",
    "\n",
    "\n",
    "**Importing the function and running it for multiple input files:**\n",
    "\n",
    "To actually run the pipeline function for multiple input files, we need to do the following:\n",
    "\n",
    "- Iterate over all the filenames in a directory\n",
    "- For each filename, call the pipeline function\n",
    "- Collect the returned results\n",
    "\n",
    "Follow the instructions in the code below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (i) Test if your pipeline function actually works\n",
    "# Import your function using the normal python syntax for imports, like this:\n",
    "#   from your_module import your_function\n",
    "# Run the function and visualize the resulting segmentation. Make sure everything\n",
    "# works as intended.\n",
    "\n",
    "# Import\n",
    "from tutorial_pipeline_solutions_batch import run_pipeline\n",
    "\n",
    "# Run\n",
    "filename = r'/home/jack/data/example_cells_1.tif'\n",
    "filename = 'example_cells_1.tif'   # XXX: DELETME!\n",
    "seg,results = run_pipeline(filename)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(seg),interpolation='none',cmap='gray',vmax=1)  # Black background\n",
    "plt.imshow(np.ma.array(seg,mask=seg==0),interpolation='none',cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) Get all relevant filenames from the directory\n",
    "# Use the function 'listdir' from the module 'os' to get a list of all the files\n",
    "# in a directory. Find a way to filter out only the relevant input files, namely\n",
    "# \"example_cells_1.tif\" and \"example_cells_2.tif\". Of course, one would usually\n",
    "# do this for many more images, otherwise it's not worth the effort.\n",
    "# Hint: Loop over the filenames and use if statements to decide which ones to \n",
    "#        keep and which ones to throw away.\n",
    "\n",
    "# Get all files\n",
    "from os import listdir\n",
    "filelist = listdir(\".\")  # \".\" stands for \"current directory\". You can put in any path.\n",
    "\n",
    "# Filter for target files: simple option\n",
    "# Note that this will use ALL files with a .tif ending, which may include files that are not\n",
    "# supposed to be used, such as previously saved segmentations!\n",
    "target_files = []\n",
    "for filename in filelist:\n",
    "    if filename.endswith('.tif'):\n",
    "        target_files.append(filename)\n",
    "\n",
    "# Filter for target files: advanced option using regex\n",
    "import re\n",
    "target_pattern = re.compile(\"^example_cells_\\d+\\.tif$\")\n",
    "target_files = [fname for fname in filelist if target_pattern.match(fname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iii) Iterate over the relevant input filenames and run the pipeline function\n",
    "# Be sure to collect the output of the pipeline function in a way that allows\n",
    "# you to trace it back to the file it came from. You could for example use a\n",
    "# dictionary with the filenames as keys.\n",
    "all_seg = {}\n",
    "all_results = {}\n",
    "for filename in target_files:\n",
    "    seg,results = run_pipeline(filename)\n",
    "    all_seg[filename] = seg\n",
    "    all_results[filename] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv) Recreate the scatterplot from above, this time with all the cells\n",
    "# You can color-code the dots to indicate which file they came from (add a legend\n",
    "# to label it explicitely).\n",
    "colors = ['blue','red']\n",
    "for key,color in zip(sorted(all_results.keys()), colors):\n",
    "    plt.scatter(all_results[key][\"cell_area\"], all_results[key][\"red_mem_mean\"],\n",
    "                linewidth=0, color=color, s=10, label=key,alpha=0.75)\n",
    "plt.legend()\n",
    "plt.xlabel(\"cell size [pxl]\")\n",
    "plt.ylabel(\"red_membrane_mean [a.u.]\")\n",
    "plt.title(\"Scatterplot with linear fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>*This is the end of the tutorial!*</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "**...but if you now just go back to your work and do nothing, you will forget all you learned within a month or two!**\n",
    "\n",
    "\n",
    "So, what to do?\n",
    "\n",
    "- Check out the **data analysis tutorial**!\n",
    "\n",
    "    - This optional tutorial showcases some possible approaches for data analysis downstream of single-cell segmentation\n",
    "    \n",
    "\n",
    "- Start applying what you have learned to your own work!\n",
    "\n",
    "\n",
    "- Stay engaged even if you currently don't need your new skills at work!\n",
    "\n",
    "    - Play around with data from your work, even if you don't need it at the moment\n",
    "\n",
    "    - Find yourself an interesting little 'pet project' to play around with\n",
    "\n",
    "    - Look for tutorials online with additional/advanced content\n",
    "    \n",
    "    - Join for seminars/events related to coding and image analysis\n",
    "        - Check out the [Bio-IT Portal](https://bio-it.embl.de/) for more info! *[internal access only]*\n",
    "        - Join the [EMBL Coding Club](https://bio-it.embl.de/coding-club/) *[internal access only]*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
